{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Prediction and TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import sys\n",
    "from tagger_net import MusicTaggerCRNN\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from math import floor\n",
    "from music_tagger_cnn import MusicTaggerCNN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import save_data, load_dataset, save_dataset, sort_result, predict_label, load_gt, plot_confusion_matrix, extract_melgrams\n",
    "\n",
    "\n",
    "# Additional for TSNE\n",
    "\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Setting the parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to set\n",
    "TRAIN = 0\n",
    "TEST = 1\n",
    "\n",
    "SAVE_MODEL = 0\n",
    "SAVE_WEIGHTS = 0\n",
    "\n",
    "LOAD_MODEL = 0\n",
    "LOAD_WEIGHTS = 1\n",
    "\n",
    "# Dataset\n",
    "MULTIFRAMES = 0\n",
    "SAVE_DB = 0\n",
    "LOAD_DB = 0\n",
    "\n",
    "# Model parameters\n",
    "nb_classes = 10\n",
    "nb_epoch = 40\n",
    "batch_size = 100\n",
    "\n",
    "time_elapsed = 0\n",
    "\n",
    "# GTZAN Dataset Tags\n",
    "tags = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "tags = np.array(tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to set\n",
    "model_name = \"crnn_net_adam_ours\"\n",
    "model_path = \"models_trained/\" + model_name + \"/\"\n",
    "weights_path = \"models_trained/\" + model_name + \"/weights/\"\n",
    "\n",
    "train_songs_list = 'lists/full_song_list.txt'\n",
    "test_songs_list = 'lists/test_songs_list_ours.txt'\n",
    "#test_songs_list = 'lists/test_songs_gtzan_list.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for the models & weights\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    print 'Path created: ', model_path\n",
    "\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "    print 'Path created: ', weights_path\n",
    "\n",
    "# Divide the song into multiple frames of 29.1s or take the center crop.\n",
    "if MULTIFRAMES:\n",
    "    train_gt_list = 'lists/train_gt_list_multiframes.txt'\n",
    "    test_gt_list = 'lists/test_gt_ours.txt'\n",
    "else:\n",
    "    train_gt_list = 'lists/train_gt_list.txt'\n",
    "    test_gt_list = 'lists/test_gt_list.txt'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiframe loading for MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_DB:\n",
    "    if MULTIFRAMES:\n",
    "        print 'Loading dataset multiframe...'\n",
    "        X_train,  y_train, num_frames_train  = load_dataset('')\n",
    "        X_test, y_test, num_frames_test = load_dataset('')\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = load_dataset('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mel-spectogram for all the frames\n",
    "else:\n",
    "    X_train, y_train, num_frames_train = extract_melgrams(train_songs_list, MULTIFRAMES, process_all_song=False, num_songs_genre=20)\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    X_test, y_test, num_frames_test = extract_melgrams(test_songs_list, MULTIFRAMES, process_all_song=False, num_songs_genre=10)\n",
    "\n",
    "\n",
    "print(X_train.shape, 'train samples')\n",
    "print(X_test.shape, 'test samples')\n",
    "\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Saving database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_DB:\n",
    "    if MULTIFRAMES:\n",
    "        save_dataset('music_dataset/music_dataset_multiframe_train.h5', X_train, y_train,num_frames_train)\n",
    "        save_dataset('music_dataset/music_dataset_multiframe_test.h5', X_test,y_test,num_frames_test)\n",
    "    else:\n",
    "        save_dataset('music_dataset/music_dataset.h5', X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print train and test information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print 'Shape labels y_train: ', Y_train.shape\n",
    "print 'Shape labels y_test: ', Y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", trainable=False, name=\"conv1\")`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(trainable=False, name=\"bn1\", axis=1)`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", trainable=False, name=\"conv2\")`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(trainable=False, name=\"bn2\", axis=1)`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", trainable=False, name=\"conv3\")`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(trainable=False, name=\"bn3\", axis=1)`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", trainable=False, name=\"conv4\")`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(trainable=False, name=\"bn4\", axis=1)`\n",
      "  '` call to the Keras 2 API: ' + signature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1044: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Unable to open file (Unable to open file: name = 'weights/music_tagger_crnn_weights_tensorflow.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-52ac65642176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Initialize model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMusicTaggerCRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'msd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1366\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#model = MusicTaggerCNN(weights='msd', input_tensor=(1, 96, 1366))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrv/MyStuff/Machine Learning/ML-SongSuggester/CRNN/tagger_net.pyc\u001b[0m in \u001b[0;36mMusicTaggerCRNN\u001b[0;34m(weights, input_tensor)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0minitial_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelgram_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         initial_model.load_weights('weights/music_tagger_crnn_weights_%s.h5' % K._BACKEND,\n\u001b[0;32m--> 137\u001b[0;31m                            by_name=True)\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Eliminate last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2476\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2478\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrv/anaconda3/envs/MLProject/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-nCYoKW-build/h5py/_objects.c:2840)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-nCYoKW-build/h5py/_objects.c:2798)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/tmp/pip-nCYoKW-build/h5py/h5f.c:2117)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (Unable to open file: name = 'weights/music_tagger_crnn_weights_tensorflow.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize model\n",
    "model = MusicTaggerCRNN(weights='msd', input_tensor=(1, 96, 1366))\n",
    "#model = MusicTaggerCNN(weights='msd', input_tensor=(1, 96, 1366))\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if LOAD_WEIGHTS:\n",
    "    model.load_weights(weights_path+model_name+'_epoch_40.h5')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Save model architecture\n",
    "if SAVE_MODEL:\n",
    "    json_string = model.to_json()\n",
    "    f = open(model_path+model_name+\".json\", 'w')\n",
    "    f.write(json_string)\n",
    "    f.close()\n",
    "\n",
    "# Train model\n",
    "if TRAIN:\n",
    "    try:\n",
    "        print (\"Training the model\")\n",
    "        f_train = open(model_path+model_name+\"_scores_training.txt\", 'w')\n",
    "        f_test = open(model_path+model_name+\"_scores_test.txt\", 'w')\n",
    "        f_scores = open(model_path+model_name+\"_scores.txt\", 'w')\n",
    "        for epoch in range(1,nb_epoch+1):\n",
    "            t0 = time.time()\n",
    "            print (\"Number of epoch: \" +str(epoch)+\"/\"+str(nb_epoch))\n",
    "            sys.stdout.flush()\n",
    "            scores = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=1, verbose=1, validation_data=(X_test, Y_test))\n",
    "            time_elapsed = time_elapsed + time.time() - t0\n",
    "            print (\"Time Elapsed: \" +str(time_elapsed))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            score_train = model.evaluate(X_train, Y_train, verbose=0)\n",
    "            print('Train Loss:', score_train[0])\n",
    "            print('Train Accuracy:', score_train[1])\n",
    "            f_train.write(str(score_train)+\"\\n\")\n",
    "\n",
    "            score_test = model.evaluate(X_test, Y_test, verbose=0)\n",
    "            print('Test Loss:', score_test[0])\n",
    "            print('Test Accuracy:', score_test[1])\n",
    "            f_test.write(str(score_test)+\"\\n\")\n",
    "\n",
    "            f_scores.write(str(score_train[0])+\",\"+str(score_train[1])+\",\"+str(score_test[0])+\",\"+str(score_test[1]) + \"\\n\")\n",
    "\n",
    "            if SAVE_WEIGHTS and epoch % 5 == 0:\n",
    "                model.save_weights(weights_path + model_name + \"_epoch_\" + str(epoch) + \".h5\")\n",
    "                print(\"Saved model to disk in: \" + weights_path + model_name + \"_epoch\" + str(epoch) + \".h5\")\n",
    "\n",
    "        f_train.close()\n",
    "        f_test.close()\n",
    "        f_scores.close()\n",
    "\n",
    "        # Save time elapsed\n",
    "        f = open(model_path+model_name+\"_time_elapsed.txt\", 'w')\n",
    "        f.write(str(time_elapsed))\n",
    "        f.close()\n",
    "\n",
    "    # Save files when an sudden close happens / ctrl C\n",
    "    except:\n",
    "        f_train.close()\n",
    "        f_test.close()\n",
    "        f_scores.close()\n",
    "        # Save time elapsed\n",
    "        f = open(model_path + model_name + \"_time_elapsed.txt\", 'w')\n",
    "        f.write(str(time_elapsed))\n",
    "        f.close()\n",
    "    finally:\n",
    "        f_train.close()\n",
    "        f_test.close()\n",
    "        f_scores.close()\n",
    "        # Save time elapsed\n",
    "        f = open(model_path + model_name + \"_time_elapsed.txt\", 'w')\n",
    "        f.write(str(time_elapsed))\n",
    "        f.close()\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    t0 = time.time()\n",
    "    print 'Predicting...','\\n'\n",
    "\n",
    "    real_labels_mean = load_gt(test_gt_list)\n",
    "    real_labels_frames = y_test\n",
    "\n",
    "    results = np.zeros((X_test.shape[0], tags.shape[0]))\n",
    "    predicted_labels_mean = np.zeros((num_frames_test.shape[0], 1))\n",
    "    predicted_labels_frames = np.zeros((y_test.shape[0], 1))\n",
    "\n",
    "\n",
    "    song_paths = open(test_songs_list, 'r').read().splitlines()\n",
    "\n",
    "    previous_numFrames = 0\n",
    "    n=0\n",
    "    for i in range(0, num_frames_test.shape[0]):\n",
    "        print song_paths[i]\n",
    "\n",
    "        num_frames=num_frames_test[i]\n",
    "        print 'Num_frames: ', str(num_frames),'\\n'\n",
    "\n",
    "        results[previous_numFrames:previous_numFrames+num_frames] = model.predict(\n",
    "            X_test[previous_numFrames:previous_numFrames+num_frames, :, :, :])\n",
    "\n",
    "\n",
    "        for j in range(previous_numFrames,previous_numFrames+num_frames):\n",
    "            #normalize the results\n",
    "            total = results[j,:].sum()\n",
    "            results[j,:]=results[j,:]/total\n",
    "            sort_result(tags, results[j,:].tolist())\n",
    "\n",
    "            predicted_label_frames=predict_label(results[j,:])\n",
    "            predicted_labels_frames[n]=predicted_label_frames\n",
    "            n+=1\n",
    "\n",
    "\n",
    "        print '\\n',\"Mean of the song: \"\n",
    "        results_song = results[previous_numFrames:previous_numFrames+num_frames]\n",
    "\n",
    "        mean=results_song.mean(0)\n",
    "        sort_result(tags, mean.tolist())\n",
    "\n",
    "        predicted_label_mean=predict_label(mean)\n",
    "\n",
    "        predicted_labels_mean[i]=predicted_label_mean\n",
    "        print '\\n','Predicted label: ', str(tags[predicted_label_mean]),'\\n'\n",
    "\n",
    "        if predicted_label_mean != real_labels_mean[i]:\n",
    "            print 'WRONG!!'\n",
    "\n",
    "\n",
    "        previous_numFrames = previous_numFrames+num_frames\n",
    "\n",
    "        #break\n",
    "        print '\\n\\n\\n'\n",
    "\n",
    "    cnf_matrix_frames = confusion_matrix(real_labels_frames, predicted_labels_frames)\n",
    "    plot_confusion_matrix(cnf_matrix_frames, classes=tags, title='Confusion matrix (frames)')\n",
    "\n",
    "    cnf_matrix_mean = confusion_matrix(real_labels_mean, predicted_labels_mean)\n",
    "    plot_confusion_matrix(cnf_matrix_mean, classes=tags, title='Confusion matrix (using mean)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy code to create features.txt\n",
    "\n",
    "l1 = []\n",
    "PATH = os.getcwd()\n",
    "data_path = PATH + '/data'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "song_data=[]\n",
    "for dataset in data_dir_list:\n",
    "    song_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the songs of dataset-'+'{}\\n'.format(dataset))\n",
    "    for song in song_list:\n",
    "        #img1 = (imageio.imread(img).astype(np.float64)/255.0)\n",
    "        #input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        #im1 = cv2.resize(input_img.astype(np.float64)/255.0, (150, 150))\n",
    "        #hog1 = pyhog.features_pedro(im1, 30)\n",
    "        \n",
    "        \n",
    "        a = np.array(hog1)\n",
    "        \n",
    "        ## Get and use array of features here\n",
    "        \n",
    "        b = a.flatten()\n",
    "        l = b.tolist()\n",
    "        \n",
    "        #print l\n",
    "        l1.append(l)\n",
    "\n",
    "song_features_arr = np.array(l1)\n",
    "print (song_features_arr.shape)\n",
    "np.savetxt('feature_vectors.txt',song_features_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "\n",
    "LOG_DIR = PATH+ '/embedding-logs'\n",
    "#metadata = os.path.join(LOG_DIR, 'metadata2.tsv')\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "feature_vectors = np.loadtxt('feature_vectors.txt')\n",
    "print (\"feature_vectors_shape:\",feature_vectors.shape)\n",
    "print (\"num of songs:\",feature_vectors.shape[0])\n",
    "print (\"size of individual feature vector:\",feature_vectors.shape[1])\n",
    "\n",
    "num_of_samples=feature_vectors.shape[0]\n",
    "print(num_of_samples)\n",
    "#num_of_samples_each_clasis = 100\n",
    "\n",
    "features = tf.Variable(feature_vectors, name='features')\n",
    "\n",
    "y = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "\n",
    "### TODO : Need to use output labels of testing to apply category information\n",
    "\n",
    "y[0:32]=0      #texas 32\n",
    "y[32:42]=1     #stop  10\n",
    "y[42:60]=2     #streetlight 18\n",
    "y[60:89]=3      #exit 29\n",
    "y[89:210]=4      #warning 121\n",
    "y[210:235]=5      #speed 25\n",
    "\n",
    "\n",
    "### This part depends on the output of testing\n",
    "\n",
    "\n",
    "print y\n",
    "\n",
    "\n",
    "#with open(metadata, 'w') as metadata_file:\n",
    "#    for row in range(210):\n",
    "#        c = y[row]\n",
    "#        metadata_file.write('{}\\n'.format(c))\n",
    "metadata_file = open(os.path.join(LOG_DIR, 'metadata_10_classes.tsv'), 'w')\n",
    "metadata_file.write('Class\\tGenre\\n')\n",
    "\n",
    "#for i in range(210):\n",
    "#    metadata_file.write('%06d\\t%s\\n' % (i, names[y[i]]))\n",
    "for i in range(num_of_samples):\n",
    "    c = tags[y[i]]\n",
    "    #print(y[i], c)\n",
    "    metadata_file.write('{}\\t{}\\n'.format(y[i],c))\n",
    "    #metadata_file.write('%06d\\t%s\\n' % (j, c))\n",
    "metadata_file.close()\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow to do TSNE display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver([features])\n",
    "\n",
    "    sess.run(features.initializer)\n",
    "    saver.save(sess, os.path.join(LOG_DIR, 'songs_10_classes.ckpt'))\n",
    "    \n",
    "    config = projector.ProjectorConfig()\n",
    "    # One can add multiple embeddings.\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = features.name\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    embedding.metadata_path = os.path.join(LOG_DIR, 'metadata_10_classes.tsv')\n",
    "    # Comment out if you don't want sprites\n",
    "    #embedding.sprite.image_path = os.path.join(LOG_DIR, 'sprite_6_classes.png')\n",
    "    #embedding.sprite.single_image_dim.extend([img_data.shape[1], img_data.shape[1]])\n",
    "    # Saves a config file that TensorBoard will read during startup.\n",
    "    projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
